{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f56a5f4-3107-444c-8ef5-da497b39bb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zyliu/miniconda3/envs/pytorch/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9244a66-7eab-419f-a9ee-85e480dcac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "                 transforms.RandomHorizontalFlip(),\n",
    "                 transforms.RandomCrop(32, 4),\n",
    "                 transforms.ToTensor(),\n",
    "                 normalize,\n",
    "                 ]), download=True),\n",
    "                 batch_size=512, shuffle=True,\n",
    "                 num_workers=4, pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "               datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "               transforms.ToTensor(),\n",
    "               normalize,\n",
    "               ])),\n",
    "               batch_size=512, shuffle=False,\n",
    "               num_workers=4, pin_memory=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b5126b-64fc-4851-9363-99652bf37466",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channel, out_channel, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
    "        self.conv3 = nn.Conv2d(out_channel, self.expansion *\n",
    "                               out_channel, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*out_channel)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channel != self.expansion*out_channel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, self.expansion*out_channel,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*out_channel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969b3dcd-949a-4e7e-a815-1e7fef511b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 128\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 128, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        # self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        # self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion*4, num_classes)\n",
    "        # self.linear = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        # out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        # out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9464dcb0-a98a-4a0d-bd14-e4326c0816ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project1_model():\n",
    "    return ResNet(Bottleneck, [2, 3, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f35d814-7e04-43fa-a6a0-1cc434c03789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 128, 32, 32]           3,456\n",
      "       BatchNorm2d-2          [-1, 128, 32, 32]             256\n",
      "            Conv2d-3          [-1, 128, 32, 32]          16,384\n",
      "       BatchNorm2d-4          [-1, 128, 32, 32]             256\n",
      "            Conv2d-5          [-1, 128, 16, 16]         147,456\n",
      "       BatchNorm2d-6          [-1, 128, 16, 16]             256\n",
      "            Conv2d-7          [-1, 512, 16, 16]          65,536\n",
      "       BatchNorm2d-8          [-1, 512, 16, 16]           1,024\n",
      "            Conv2d-9          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-10          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-11          [-1, 512, 16, 16]               0\n",
      "           Conv2d-12          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-13          [-1, 128, 16, 16]             256\n",
      "           Conv2d-14          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-15          [-1, 128, 16, 16]             256\n",
      "           Conv2d-16          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-17          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-18          [-1, 512, 16, 16]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "           Conv2d-23          [-1, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-24          [-1, 512, 16, 16]           1,024\n",
      "       Bottleneck-25          [-1, 512, 16, 16]               0\n",
      "           Conv2d-26          [-1, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-27          [-1, 256, 16, 16]             512\n",
      "           Conv2d-28            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-29            [-1, 256, 8, 8]             512\n",
      "           Conv2d-30           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-31           [-1, 1024, 8, 8]           2,048\n",
      "           Conv2d-32           [-1, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-33           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-34           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-35            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "           Conv2d-37            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-38            [-1, 256, 8, 8]             512\n",
      "           Conv2d-39           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-40           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-41           [-1, 1024, 8, 8]               0\n",
      "           Conv2d-42            [-1, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-43            [-1, 256, 8, 8]             512\n",
      "           Conv2d-44            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 8, 8]             512\n",
      "           Conv2d-46           [-1, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-47           [-1, 1024, 8, 8]           2,048\n",
      "       Bottleneck-48           [-1, 1024, 8, 8]               0\n",
      "           Linear-49                   [-1, 10]          40,970\n",
      "================================================================\n",
      "Total params: 4,649,098\n",
      "Trainable params: 4,649,098\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 25.25\n",
      "Params size (MB): 17.73\n",
      "Estimated Total Size (MB): 43.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = project1_model().to(device)\n",
    "summary(model, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d711ca1c-34bf-4249-9293-2bca3a2ec9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetParams:\n",
    "   \"\"\"\n",
    "    A class to pass the hyperparameters to the model\n",
    "   \"\"\"\n",
    "   def __init__(self, arch='Model 1' ,epochs=100, start_epoch=0, batch_size=512, lr=0.1, momentum=0.9, weight_decay=1e-4, print_freq=50,\n",
    "                save_dir='save_temporary_checkpoints', save_every=10):\n",
    "        self.save_every = save_every #Saves checkpoints at every specified number of epochs\n",
    "        self.save_dir = save_dir #The directory used to save the trained models\n",
    "        self.print_freq = print_freq #print frequency \n",
    "        self.weight_decay = weight_decay #Weight decay for SGD\n",
    "        self.momentum = momentum #Momentum for SGD\n",
    "        self.lr = lr #Learning Rate\n",
    "        self.batch_size = batch_size #Batch Size for each epoch \n",
    "        self.start_epoch = start_epoch #Starting Epoch\n",
    "        self.epochs = epochs #Total Epochs\n",
    "        self.arch = arch #ResNet model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2d70bc-b3c1-4687-bbf4-971a161b586a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epochs():\n",
    "    global args, best_precision\n",
    "    #Check if the save_dir exists or not\n",
    "    if not os.path.exists(args.save_dir):\n",
    "        os.makedirs(args.save_dir)\n",
    "    #Loading the model \n",
    "    model = project1_model()\n",
    "    model.cuda()\n",
    "\n",
    "    #Defining the Loss Function\n",
    "    loss_func = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    #Defining the Optimizer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), args.lr, betas=(0.9, 0.99))\n",
    "    \n",
    "    #Defining the Learning Rate Scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                        milestones=[100, 150], last_epoch=args.start_epoch - 1)\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        #Train for one epoch\n",
    "        print('Training model: {}'.format(args.arch))\n",
    "        print('Current Learning Rate {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        train(train_loader, model, loss_func, optimizer, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        #Test for one epoch\n",
    "        precision = validate(val_loader, model, loss_func)\n",
    "\n",
    "        #Save the best precision and make a checkpoint\n",
    "        is_best = precision > best_precision\n",
    "        best_precision = max(precision, best_precision)\n",
    "        if epoch > 0 and epoch % args.save_every == 0:\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_dir, 'project1_model_checkpoint.th'))\n",
    "        if is_best:\n",
    "            torch.save(model.state_dict(), os.path.join(args.save_dir, 'project1_model.th'))\n",
    "    return best_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c6ca600-7ed6-491a-bb1c-c80fc1446897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeepAverages(object):\n",
    "    #Computes and stores the average along with the current value\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f4ab67-10a8-4f19-a7b8-b7dddeca5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    #Computes the top 1 precision\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def validate(val_loader, model, loss_func):\n",
    "    #Run an Evaluation\n",
    "    batch_time = KeepAverages()\n",
    "    losses = KeepAverages()\n",
    "    top1 = KeepAverages()\n",
    "\n",
    "    #Switch to Evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "            #Compute the output of the Model and calculate the Loss\n",
    "            output = model(input_var)\n",
    "            loss = loss_func(output, target_var)\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            #Measure the Loss and Update it \n",
    "            precision = accuracy(output.data, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(precision.item(), input.size(0))\n",
    "\n",
    "            #Measure the elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "\n",
    "    print('Test Accuracy\\t  Top Precision: {top1.avg:.3f} (Error: {error:.3f} )\\n'\n",
    "          .format(top1=top1,error=100-top1.avg))\n",
    "    val_losses.append(100-top1.avg)\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648d79b4-acfe-4461-9592-6a8126bddf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, loss_func, optimizer, epoch):\n",
    "    #Run one training epoch\n",
    "\n",
    "    batch_time = KeepAverages()\n",
    "    data_time = KeepAverages()\n",
    "    losses = KeepAverages()\n",
    "    top1 = KeepAverages()\n",
    "\n",
    "    #Switch to Train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # Measure the data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        target = target.cuda()\n",
    "        input_var = input.cuda()\n",
    "        target_var = target\n",
    "\n",
    "        #Compute the output and the Loss\n",
    "        output = model(input_var)\n",
    "        loss = loss_func(output, target_var)\n",
    "\n",
    "        #Compute the Gradient and do an SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        \n",
    "        #Measure the accuracy and record the loss\n",
    "        precision = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(precision.item(), input.size(0))\n",
    "\n",
    "        #Measure the Elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print('Epoch: No: [{0}] Batches: [{1}/{2}]\\t'\n",
    "                  'Loss: {loss.val:.4f} (Average: {loss.avg:.4f})\\t'\n",
    "                  'Precision: {top1.val:.3f} (Average: {top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1))\n",
    "    train_losses.append(100-top1.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ebf3777-92f6-4855-baa8-0df7af075742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "  #Function to show an image\n",
    "  %matplotlib inline\n",
    "  %config InlineBackend.figure_format = 'retina'\n",
    "  img = img / 2 + 0.5     # un - Normalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858ed804-c53a-478d-bb30-7bb9a7d397dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [0] Batches: [0/98]\tLoss: 2.4778 (Average: 2.4778)\tPrecision: 11.523 (Average: 11.523)\n",
      "Epoch: No: [0] Batches: [50/98]\tLoss: 2.1210 (Average: 19.9052)\tPrecision: 19.336 (Average: 13.691)\n",
      "Test Accuracy\t  Top Precision: 28.650 (Error: 71.350 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [1] Batches: [0/98]\tLoss: 1.9975 (Average: 1.9975)\tPrecision: 26.367 (Average: 26.367)\n",
      "Epoch: No: [1] Batches: [50/98]\tLoss: 1.9185 (Average: 1.9147)\tPrecision: 27.930 (Average: 29.917)\n",
      "Test Accuracy\t  Top Precision: 35.370 (Error: 64.630 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [2] Batches: [0/98]\tLoss: 1.8748 (Average: 1.8748)\tPrecision: 29.492 (Average: 29.492)\n",
      "Epoch: No: [2] Batches: [50/98]\tLoss: 1.7175 (Average: 1.7809)\tPrecision: 33.789 (Average: 33.536)\n",
      "Test Accuracy\t  Top Precision: 29.990 (Error: 70.010 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [3] Batches: [0/98]\tLoss: 1.7332 (Average: 1.7332)\tPrecision: 32.031 (Average: 32.031)\n",
      "Epoch: No: [3] Batches: [50/98]\tLoss: 1.7306 (Average: 1.6950)\tPrecision: 40.039 (Average: 36.941)\n",
      "Test Accuracy\t  Top Precision: 38.030 (Error: 61.970 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [4] Batches: [0/98]\tLoss: 1.6233 (Average: 1.6233)\tPrecision: 38.867 (Average: 38.867)\n",
      "Epoch: No: [4] Batches: [50/98]\tLoss: 1.6284 (Average: 1.6218)\tPrecision: 36.719 (Average: 39.959)\n",
      "Test Accuracy\t  Top Precision: 39.530 (Error: 60.470 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [5] Batches: [0/98]\tLoss: 1.5567 (Average: 1.5567)\tPrecision: 44.141 (Average: 44.141)\n",
      "Epoch: No: [5] Batches: [50/98]\tLoss: 1.4993 (Average: 1.5525)\tPrecision: 43.164 (Average: 42.590)\n",
      "Test Accuracy\t  Top Precision: 39.120 (Error: 60.880 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [6] Batches: [0/98]\tLoss: 1.4659 (Average: 1.4659)\tPrecision: 46.484 (Average: 46.484)\n",
      "Epoch: No: [6] Batches: [50/98]\tLoss: 1.4488 (Average: 1.4813)\tPrecision: 47.070 (Average: 45.910)\n",
      "Test Accuracy\t  Top Precision: 47.370 (Error: 52.630 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [7] Batches: [0/98]\tLoss: 1.4135 (Average: 1.4135)\tPrecision: 48.438 (Average: 48.438)\n",
      "Epoch: No: [7] Batches: [50/98]\tLoss: 1.3681 (Average: 1.3806)\tPrecision: 51.758 (Average: 49.950)\n",
      "Test Accuracy\t  Top Precision: 52.330 (Error: 47.670 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [8] Batches: [0/98]\tLoss: 1.3602 (Average: 1.3602)\tPrecision: 54.297 (Average: 54.297)\n",
      "Epoch: No: [8] Batches: [50/98]\tLoss: 1.3018 (Average: 1.2698)\tPrecision: 52.930 (Average: 54.163)\n",
      "Test Accuracy\t  Top Precision: 50.090 (Error: 49.910 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [9] Batches: [0/98]\tLoss: 1.2287 (Average: 1.2287)\tPrecision: 57.812 (Average: 57.812)\n",
      "Epoch: No: [9] Batches: [50/98]\tLoss: 1.2566 (Average: 1.1614)\tPrecision: 57.031 (Average: 58.609)\n",
      "Test Accuracy\t  Top Precision: 56.830 (Error: 43.170 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [10] Batches: [0/98]\tLoss: 1.0673 (Average: 1.0673)\tPrecision: 61.719 (Average: 61.719)\n",
      "Epoch: No: [10] Batches: [50/98]\tLoss: 1.1263 (Average: 1.0574)\tPrecision: 61.133 (Average: 62.270)\n",
      "Test Accuracy\t  Top Precision: 62.020 (Error: 37.980 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [11] Batches: [0/98]\tLoss: 1.0141 (Average: 1.0141)\tPrecision: 62.109 (Average: 62.109)\n",
      "Epoch: No: [11] Batches: [50/98]\tLoss: 0.9757 (Average: 0.9828)\tPrecision: 65.625 (Average: 64.874)\n",
      "Test Accuracy\t  Top Precision: 64.240 (Error: 35.760 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [12] Batches: [0/98]\tLoss: 0.9460 (Average: 0.9460)\tPrecision: 67.383 (Average: 67.383)\n",
      "Epoch: No: [12] Batches: [50/98]\tLoss: 0.9266 (Average: 0.9292)\tPrecision: 67.578 (Average: 67.069)\n",
      "Test Accuracy\t  Top Precision: 66.290 (Error: 33.710 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [13] Batches: [0/98]\tLoss: 0.8462 (Average: 0.8462)\tPrecision: 69.336 (Average: 69.336)\n",
      "Epoch: No: [13] Batches: [50/98]\tLoss: 0.8461 (Average: 0.8945)\tPrecision: 69.531 (Average: 68.421)\n",
      "Test Accuracy\t  Top Precision: 65.920 (Error: 34.080 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [14] Batches: [0/98]\tLoss: 0.8895 (Average: 0.8895)\tPrecision: 72.461 (Average: 72.461)\n",
      "Epoch: No: [14] Batches: [50/98]\tLoss: 0.7630 (Average: 0.8202)\tPrecision: 72.070 (Average: 70.941)\n",
      "Test Accuracy\t  Top Precision: 68.120 (Error: 31.880 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [15] Batches: [0/98]\tLoss: 0.8456 (Average: 0.8456)\tPrecision: 72.070 (Average: 72.070)\n",
      "Epoch: No: [15] Batches: [50/98]\tLoss: 0.7861 (Average: 0.7794)\tPrecision: 70.898 (Average: 72.465)\n",
      "Test Accuracy\t  Top Precision: 69.980 (Error: 30.020 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [16] Batches: [0/98]\tLoss: 0.8066 (Average: 0.8066)\tPrecision: 70.898 (Average: 70.898)\n",
      "Epoch: No: [16] Batches: [50/98]\tLoss: 0.7740 (Average: 0.7354)\tPrecision: 73.633 (Average: 74.226)\n",
      "Test Accuracy\t  Top Precision: 73.370 (Error: 26.630 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [17] Batches: [0/98]\tLoss: 0.6388 (Average: 0.6388)\tPrecision: 77.734 (Average: 77.734)\n",
      "Epoch: No: [17] Batches: [50/98]\tLoss: 0.7090 (Average: 0.6991)\tPrecision: 75.586 (Average: 75.996)\n",
      "Test Accuracy\t  Top Precision: 73.760 (Error: 26.240 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [18] Batches: [0/98]\tLoss: 0.6207 (Average: 0.6207)\tPrecision: 78.711 (Average: 78.711)\n",
      "Epoch: No: [18] Batches: [50/98]\tLoss: 0.5964 (Average: 0.6535)\tPrecision: 79.688 (Average: 76.922)\n",
      "Test Accuracy\t  Top Precision: 65.820 (Error: 34.180 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [19] Batches: [0/98]\tLoss: 0.6845 (Average: 0.6845)\tPrecision: 78.516 (Average: 78.516)\n",
      "Epoch: No: [19] Batches: [50/98]\tLoss: 0.6299 (Average: 0.6267)\tPrecision: 78.906 (Average: 78.370)\n",
      "Test Accuracy\t  Top Precision: 73.870 (Error: 26.130 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [20] Batches: [0/98]\tLoss: 0.6617 (Average: 0.6617)\tPrecision: 75.781 (Average: 75.781)\n",
      "Epoch: No: [20] Batches: [50/98]\tLoss: 0.5623 (Average: 0.6141)\tPrecision: 80.078 (Average: 78.956)\n",
      "Test Accuracy\t  Top Precision: 72.410 (Error: 27.590 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [21] Batches: [0/98]\tLoss: 0.5068 (Average: 0.5068)\tPrecision: 80.469 (Average: 80.469)\n",
      "Epoch: No: [21] Batches: [50/98]\tLoss: 0.5304 (Average: 0.5740)\tPrecision: 79.492 (Average: 79.875)\n",
      "Test Accuracy\t  Top Precision: 77.850 (Error: 22.150 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [22] Batches: [0/98]\tLoss: 0.5825 (Average: 0.5825)\tPrecision: 79.297 (Average: 79.297)\n",
      "Epoch: No: [22] Batches: [50/98]\tLoss: 0.4565 (Average: 0.5559)\tPrecision: 83.594 (Average: 80.672)\n",
      "Test Accuracy\t  Top Precision: 77.420 (Error: 22.580 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [23] Batches: [0/98]\tLoss: 0.4623 (Average: 0.4623)\tPrecision: 85.156 (Average: 85.156)\n",
      "Epoch: No: [23] Batches: [50/98]\tLoss: 0.6129 (Average: 0.5439)\tPrecision: 77.930 (Average: 81.200)\n",
      "Test Accuracy\t  Top Precision: 74.410 (Error: 25.590 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [24] Batches: [0/98]\tLoss: 0.5093 (Average: 0.5093)\tPrecision: 80.859 (Average: 80.859)\n",
      "Epoch: No: [24] Batches: [50/98]\tLoss: 0.4939 (Average: 0.5170)\tPrecision: 82.617 (Average: 82.131)\n",
      "Test Accuracy\t  Top Precision: 78.070 (Error: 21.930 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [25] Batches: [0/98]\tLoss: 0.4268 (Average: 0.4268)\tPrecision: 86.133 (Average: 86.133)\n",
      "Epoch: No: [25] Batches: [50/98]\tLoss: 0.5918 (Average: 0.5115)\tPrecision: 81.055 (Average: 82.479)\n",
      "Test Accuracy\t  Top Precision: 79.230 (Error: 20.770 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [26] Batches: [0/98]\tLoss: 0.4480 (Average: 0.4480)\tPrecision: 85.547 (Average: 85.547)\n",
      "Epoch: No: [26] Batches: [50/98]\tLoss: 0.4214 (Average: 0.4881)\tPrecision: 84.180 (Average: 82.935)\n",
      "Test Accuracy\t  Top Precision: 77.630 (Error: 22.370 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [27] Batches: [0/98]\tLoss: 0.4627 (Average: 0.4627)\tPrecision: 83.594 (Average: 83.594)\n",
      "Epoch: No: [27] Batches: [50/98]\tLoss: 0.4375 (Average: 0.4783)\tPrecision: 84.375 (Average: 83.513)\n",
      "Test Accuracy\t  Top Precision: 79.490 (Error: 20.510 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [28] Batches: [0/98]\tLoss: 0.4726 (Average: 0.4726)\tPrecision: 84.766 (Average: 84.766)\n",
      "Epoch: No: [28] Batches: [50/98]\tLoss: 0.4775 (Average: 0.4708)\tPrecision: 84.180 (Average: 83.624)\n",
      "Test Accuracy\t  Top Precision: 79.600 (Error: 20.400 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [29] Batches: [0/98]\tLoss: 0.5326 (Average: 0.5326)\tPrecision: 80.273 (Average: 80.273)\n",
      "Epoch: No: [29] Batches: [50/98]\tLoss: 0.5346 (Average: 0.4558)\tPrecision: 82.422 (Average: 84.088)\n",
      "Test Accuracy\t  Top Precision: 80.350 (Error: 19.650 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [30] Batches: [0/98]\tLoss: 0.4555 (Average: 0.4555)\tPrecision: 83.984 (Average: 83.984)\n",
      "Epoch: No: [30] Batches: [50/98]\tLoss: 0.3896 (Average: 0.4509)\tPrecision: 86.719 (Average: 84.708)\n",
      "Test Accuracy\t  Top Precision: 81.450 (Error: 18.550 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [31] Batches: [0/98]\tLoss: 0.4486 (Average: 0.4486)\tPrecision: 84.766 (Average: 84.766)\n",
      "Epoch: No: [31] Batches: [50/98]\tLoss: 0.4462 (Average: 0.4383)\tPrecision: 84.570 (Average: 84.854)\n",
      "Test Accuracy\t  Top Precision: 81.100 (Error: 18.900 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [32] Batches: [0/98]\tLoss: 0.3690 (Average: 0.3690)\tPrecision: 88.672 (Average: 88.672)\n",
      "Epoch: No: [32] Batches: [50/98]\tLoss: 0.5004 (Average: 0.4192)\tPrecision: 83.203 (Average: 85.409)\n",
      "Test Accuracy\t  Top Precision: 80.940 (Error: 19.060 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [33] Batches: [0/98]\tLoss: 0.4070 (Average: 0.4070)\tPrecision: 85.547 (Average: 85.547)\n",
      "Epoch: No: [33] Batches: [50/98]\tLoss: 0.3187 (Average: 0.4202)\tPrecision: 89.062 (Average: 85.478)\n",
      "Test Accuracy\t  Top Precision: 81.390 (Error: 18.610 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [34] Batches: [0/98]\tLoss: 0.3834 (Average: 0.3834)\tPrecision: 86.328 (Average: 86.328)\n",
      "Epoch: No: [34] Batches: [50/98]\tLoss: 0.4558 (Average: 0.4180)\tPrecision: 85.352 (Average: 85.658)\n",
      "Test Accuracy\t  Top Precision: 82.230 (Error: 17.770 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [35] Batches: [0/98]\tLoss: 0.3774 (Average: 0.3774)\tPrecision: 87.305 (Average: 87.305)\n",
      "Epoch: No: [35] Batches: [50/98]\tLoss: 0.3868 (Average: 0.3888)\tPrecision: 87.109 (Average: 86.657)\n",
      "Test Accuracy\t  Top Precision: 81.790 (Error: 18.210 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [36] Batches: [0/98]\tLoss: 0.3340 (Average: 0.3340)\tPrecision: 88.672 (Average: 88.672)\n",
      "Epoch: No: [36] Batches: [50/98]\tLoss: 0.3933 (Average: 0.4028)\tPrecision: 84.961 (Average: 85.964)\n",
      "Test Accuracy\t  Top Precision: 80.000 (Error: 20.000 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [37] Batches: [0/98]\tLoss: 0.4390 (Average: 0.4390)\tPrecision: 85.742 (Average: 85.742)\n",
      "Epoch: No: [37] Batches: [50/98]\tLoss: 0.4092 (Average: 0.3687)\tPrecision: 86.719 (Average: 87.144)\n",
      "Test Accuracy\t  Top Precision: 81.330 (Error: 18.670 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [38] Batches: [0/98]\tLoss: 0.3846 (Average: 0.3846)\tPrecision: 87.500 (Average: 87.500)\n",
      "Epoch: No: [38] Batches: [50/98]\tLoss: 0.3656 (Average: 0.3656)\tPrecision: 87.500 (Average: 87.381)\n",
      "Test Accuracy\t  Top Precision: 79.310 (Error: 20.690 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [39] Batches: [0/98]\tLoss: 0.3739 (Average: 0.3739)\tPrecision: 87.305 (Average: 87.305)\n",
      "Epoch: No: [39] Batches: [50/98]\tLoss: 0.4450 (Average: 0.3732)\tPrecision: 84.180 (Average: 87.083)\n",
      "Test Accuracy\t  Top Precision: 83.490 (Error: 16.510 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [40] Batches: [0/98]\tLoss: 0.3501 (Average: 0.3501)\tPrecision: 87.109 (Average: 87.109)\n",
      "Epoch: No: [40] Batches: [50/98]\tLoss: 0.4084 (Average: 0.3651)\tPrecision: 86.719 (Average: 87.190)\n",
      "Test Accuracy\t  Top Precision: 80.490 (Error: 19.510 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [41] Batches: [0/98]\tLoss: 0.2626 (Average: 0.2626)\tPrecision: 91.016 (Average: 91.016)\n",
      "Epoch: No: [41] Batches: [50/98]\tLoss: 0.4111 (Average: 0.3470)\tPrecision: 86.133 (Average: 87.879)\n",
      "Test Accuracy\t  Top Precision: 83.620 (Error: 16.380 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [42] Batches: [0/98]\tLoss: 0.3044 (Average: 0.3044)\tPrecision: 90.039 (Average: 90.039)\n",
      "Epoch: No: [42] Batches: [50/98]\tLoss: 0.3347 (Average: 0.3458)\tPrecision: 89.062 (Average: 87.948)\n",
      "Test Accuracy\t  Top Precision: 82.750 (Error: 17.250 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [43] Batches: [0/98]\tLoss: 0.3171 (Average: 0.3171)\tPrecision: 89.648 (Average: 89.648)\n",
      "Epoch: No: [43] Batches: [50/98]\tLoss: 0.3361 (Average: 0.3414)\tPrecision: 87.305 (Average: 88.174)\n",
      "Test Accuracy\t  Top Precision: 82.030 (Error: 17.970 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [44] Batches: [0/98]\tLoss: 0.3775 (Average: 0.3775)\tPrecision: 88.477 (Average: 88.477)\n",
      "Epoch: No: [44] Batches: [50/98]\tLoss: 0.4177 (Average: 0.3307)\tPrecision: 86.523 (Average: 88.343)\n",
      "Test Accuracy\t  Top Precision: 83.780 (Error: 16.220 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [45] Batches: [0/98]\tLoss: 0.3780 (Average: 0.3780)\tPrecision: 87.305 (Average: 87.305)\n",
      "Epoch: No: [45] Batches: [50/98]\tLoss: 0.3371 (Average: 0.3264)\tPrecision: 88.867 (Average: 88.706)\n",
      "Test Accuracy\t  Top Precision: 82.380 (Error: 17.620 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [46] Batches: [0/98]\tLoss: 0.3028 (Average: 0.3028)\tPrecision: 90.039 (Average: 90.039)\n",
      "Epoch: No: [46] Batches: [50/98]\tLoss: 0.2870 (Average: 0.3187)\tPrecision: 88.086 (Average: 88.909)\n",
      "Test Accuracy\t  Top Precision: 84.000 (Error: 16.000 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [47] Batches: [0/98]\tLoss: 0.2484 (Average: 0.2484)\tPrecision: 91.797 (Average: 91.797)\n",
      "Epoch: No: [47] Batches: [50/98]\tLoss: 0.2793 (Average: 0.3282)\tPrecision: 90.039 (Average: 88.381)\n",
      "Test Accuracy\t  Top Precision: 83.710 (Error: 16.290 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [48] Batches: [0/98]\tLoss: 0.3048 (Average: 0.3048)\tPrecision: 89.648 (Average: 89.648)\n",
      "Epoch: No: [48] Batches: [50/98]\tLoss: 0.3753 (Average: 0.3178)\tPrecision: 85.742 (Average: 88.821)\n",
      "Test Accuracy\t  Top Precision: 84.320 (Error: 15.680 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [49] Batches: [0/98]\tLoss: 0.2410 (Average: 0.2410)\tPrecision: 91.406 (Average: 91.406)\n",
      "Epoch: No: [49] Batches: [50/98]\tLoss: 0.3510 (Average: 0.3184)\tPrecision: 86.133 (Average: 88.844)\n",
      "Test Accuracy\t  Top Precision: 84.290 (Error: 15.710 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [50] Batches: [0/98]\tLoss: 0.2473 (Average: 0.2473)\tPrecision: 90.234 (Average: 90.234)\n",
      "Epoch: No: [50] Batches: [50/98]\tLoss: 0.2717 (Average: 0.2955)\tPrecision: 89.648 (Average: 89.790)\n",
      "Test Accuracy\t  Top Precision: 85.040 (Error: 14.960 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [51] Batches: [0/98]\tLoss: 0.3115 (Average: 0.3115)\tPrecision: 89.258 (Average: 89.258)\n",
      "Epoch: No: [51] Batches: [50/98]\tLoss: 0.3320 (Average: 0.3037)\tPrecision: 89.062 (Average: 89.208)\n",
      "Test Accuracy\t  Top Precision: 84.570 (Error: 15.430 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [52] Batches: [0/98]\tLoss: 0.2694 (Average: 0.2694)\tPrecision: 91.211 (Average: 91.211)\n",
      "Epoch: No: [52] Batches: [50/98]\tLoss: 0.3084 (Average: 0.2979)\tPrecision: 89.258 (Average: 89.622)\n",
      "Test Accuracy\t  Top Precision: 83.600 (Error: 16.400 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [53] Batches: [0/98]\tLoss: 0.2828 (Average: 0.2828)\tPrecision: 89.648 (Average: 89.648)\n",
      "Epoch: No: [53] Batches: [50/98]\tLoss: 0.3044 (Average: 0.2917)\tPrecision: 90.625 (Average: 89.882)\n",
      "Test Accuracy\t  Top Precision: 84.730 (Error: 15.270 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [54] Batches: [0/98]\tLoss: 0.2793 (Average: 0.2793)\tPrecision: 89.648 (Average: 89.648)\n",
      "Epoch: No: [54] Batches: [50/98]\tLoss: 0.2401 (Average: 0.2671)\tPrecision: 90.820 (Average: 90.598)\n",
      "Test Accuracy\t  Top Precision: 81.180 (Error: 18.820 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [55] Batches: [0/98]\tLoss: 0.3927 (Average: 0.3927)\tPrecision: 88.867 (Average: 88.867)\n",
      "Epoch: No: [55] Batches: [50/98]\tLoss: 0.2885 (Average: 0.2753)\tPrecision: 91.211 (Average: 90.296)\n",
      "Test Accuracy\t  Top Precision: 82.570 (Error: 17.430 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [56] Batches: [0/98]\tLoss: 0.2584 (Average: 0.2584)\tPrecision: 91.797 (Average: 91.797)\n",
      "Epoch: No: [56] Batches: [50/98]\tLoss: 0.3064 (Average: 0.2714)\tPrecision: 90.625 (Average: 90.514)\n",
      "Test Accuracy\t  Top Precision: 83.960 (Error: 16.040 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [57] Batches: [0/98]\tLoss: 0.2460 (Average: 0.2460)\tPrecision: 92.188 (Average: 92.188)\n",
      "Epoch: No: [57] Batches: [50/98]\tLoss: 0.2918 (Average: 0.2693)\tPrecision: 89.648 (Average: 90.648)\n",
      "Test Accuracy\t  Top Precision: 85.130 (Error: 14.870 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [58] Batches: [0/98]\tLoss: 0.3013 (Average: 0.3013)\tPrecision: 90.234 (Average: 90.234)\n",
      "Epoch: No: [58] Batches: [50/98]\tLoss: 0.3445 (Average: 0.2783)\tPrecision: 88.672 (Average: 90.150)\n",
      "Test Accuracy\t  Top Precision: 83.420 (Error: 16.580 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [59] Batches: [0/98]\tLoss: 0.2167 (Average: 0.2167)\tPrecision: 92.188 (Average: 92.188)\n",
      "Epoch: No: [59] Batches: [50/98]\tLoss: 0.2976 (Average: 0.2719)\tPrecision: 90.234 (Average: 90.483)\n",
      "Test Accuracy\t  Top Precision: 84.410 (Error: 15.590 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [60] Batches: [0/98]\tLoss: 0.2525 (Average: 0.2525)\tPrecision: 91.602 (Average: 91.602)\n",
      "Epoch: No: [60] Batches: [50/98]\tLoss: 0.2385 (Average: 0.2591)\tPrecision: 91.992 (Average: 91.058)\n",
      "Test Accuracy\t  Top Precision: 80.580 (Error: 19.420 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [61] Batches: [0/98]\tLoss: 0.2785 (Average: 0.2785)\tPrecision: 90.039 (Average: 90.039)\n",
      "Epoch: No: [61] Batches: [50/98]\tLoss: 0.3084 (Average: 0.2685)\tPrecision: 88.281 (Average: 90.529)\n",
      "Test Accuracy\t  Top Precision: 85.900 (Error: 14.100 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [62] Batches: [0/98]\tLoss: 0.1668 (Average: 0.1668)\tPrecision: 94.531 (Average: 94.531)\n",
      "Epoch: No: [62] Batches: [50/98]\tLoss: 0.3278 (Average: 0.2469)\tPrecision: 87.500 (Average: 91.184)\n",
      "Test Accuracy\t  Top Precision: 85.870 (Error: 14.130 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [63] Batches: [0/98]\tLoss: 0.1977 (Average: 0.1977)\tPrecision: 92.383 (Average: 92.383)\n",
      "Epoch: No: [63] Batches: [50/98]\tLoss: 0.2288 (Average: 0.2420)\tPrecision: 91.797 (Average: 91.732)\n",
      "Test Accuracy\t  Top Precision: 84.870 (Error: 15.130 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [64] Batches: [0/98]\tLoss: 0.2371 (Average: 0.2371)\tPrecision: 92.383 (Average: 92.383)\n",
      "Epoch: No: [64] Batches: [50/98]\tLoss: 0.2820 (Average: 0.2462)\tPrecision: 89.844 (Average: 91.468)\n",
      "Test Accuracy\t  Top Precision: 86.580 (Error: 13.420 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [65] Batches: [0/98]\tLoss: 0.1806 (Average: 0.1806)\tPrecision: 93.555 (Average: 93.555)\n",
      "Epoch: No: [65] Batches: [50/98]\tLoss: 0.2228 (Average: 0.2405)\tPrecision: 91.211 (Average: 91.617)\n",
      "Test Accuracy\t  Top Precision: 86.040 (Error: 13.960 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [66] Batches: [0/98]\tLoss: 0.2216 (Average: 0.2216)\tPrecision: 90.625 (Average: 90.625)\n",
      "Epoch: No: [66] Batches: [50/98]\tLoss: 0.2272 (Average: 0.2380)\tPrecision: 92.383 (Average: 91.693)\n",
      "Test Accuracy\t  Top Precision: 86.540 (Error: 13.460 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [67] Batches: [0/98]\tLoss: 0.2054 (Average: 0.2054)\tPrecision: 92.383 (Average: 92.383)\n",
      "Epoch: No: [67] Batches: [50/98]\tLoss: 0.1875 (Average: 0.2295)\tPrecision: 93.555 (Average: 91.973)\n",
      "Test Accuracy\t  Top Precision: 86.180 (Error: 13.820 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [68] Batches: [0/98]\tLoss: 0.2108 (Average: 0.2108)\tPrecision: 91.992 (Average: 91.992)\n",
      "Epoch: No: [68] Batches: [50/98]\tLoss: 0.1996 (Average: 0.2267)\tPrecision: 91.797 (Average: 91.992)\n",
      "Test Accuracy\t  Top Precision: 85.980 (Error: 14.020 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [69] Batches: [0/98]\tLoss: 0.1851 (Average: 0.1851)\tPrecision: 93.945 (Average: 93.945)\n",
      "Epoch: No: [69] Batches: [50/98]\tLoss: 0.2221 (Average: 0.2230)\tPrecision: 92.578 (Average: 92.107)\n",
      "Test Accuracy\t  Top Precision: 85.670 (Error: 14.330 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [70] Batches: [0/98]\tLoss: 0.2080 (Average: 0.2080)\tPrecision: 92.578 (Average: 92.578)\n",
      "Epoch: No: [70] Batches: [50/98]\tLoss: 0.3120 (Average: 0.2301)\tPrecision: 88.672 (Average: 92.034)\n",
      "Test Accuracy\t  Top Precision: 84.250 (Error: 15.750 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [71] Batches: [0/98]\tLoss: 0.2617 (Average: 0.2617)\tPrecision: 91.211 (Average: 91.211)\n",
      "Epoch: No: [71] Batches: [50/98]\tLoss: 0.2148 (Average: 0.2306)\tPrecision: 91.797 (Average: 91.820)\n",
      "Test Accuracy\t  Top Precision: 86.250 (Error: 13.750 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [72] Batches: [0/98]\tLoss: 0.2394 (Average: 0.2394)\tPrecision: 92.383 (Average: 92.383)\n",
      "Epoch: No: [72] Batches: [50/98]\tLoss: 0.2055 (Average: 0.2267)\tPrecision: 92.383 (Average: 91.996)\n",
      "Test Accuracy\t  Top Precision: 85.770 (Error: 14.230 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [73] Batches: [0/98]\tLoss: 0.2300 (Average: 0.2300)\tPrecision: 93.555 (Average: 93.555)\n",
      "Epoch: No: [73] Batches: [50/98]\tLoss: 0.2214 (Average: 0.2097)\tPrecision: 90.820 (Average: 92.643)\n",
      "Test Accuracy\t  Top Precision: 84.830 (Error: 15.170 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [74] Batches: [0/98]\tLoss: 0.2007 (Average: 0.2007)\tPrecision: 92.773 (Average: 92.773)\n",
      "Epoch: No: [74] Batches: [50/98]\tLoss: 0.2475 (Average: 0.2360)\tPrecision: 91.992 (Average: 91.778)\n",
      "Test Accuracy\t  Top Precision: 86.360 (Error: 13.640 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [75] Batches: [0/98]\tLoss: 0.1933 (Average: 0.1933)\tPrecision: 91.406 (Average: 91.406)\n",
      "Epoch: No: [75] Batches: [50/98]\tLoss: 0.1415 (Average: 0.2148)\tPrecision: 95.312 (Average: 92.471)\n",
      "Test Accuracy\t  Top Precision: 85.010 (Error: 14.990 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [76] Batches: [0/98]\tLoss: 0.2107 (Average: 0.2107)\tPrecision: 92.383 (Average: 92.383)\n",
      "Epoch: No: [76] Batches: [50/98]\tLoss: 0.1907 (Average: 0.1969)\tPrecision: 93.359 (Average: 93.076)\n",
      "Test Accuracy\t  Top Precision: 86.590 (Error: 13.410 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [77] Batches: [0/98]\tLoss: 0.1916 (Average: 0.1916)\tPrecision: 93.750 (Average: 93.750)\n",
      "Epoch: No: [77] Batches: [50/98]\tLoss: 0.1631 (Average: 0.1879)\tPrecision: 94.141 (Average: 93.417)\n",
      "Test Accuracy\t  Top Precision: 83.680 (Error: 16.320 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [78] Batches: [0/98]\tLoss: 0.2115 (Average: 0.2115)\tPrecision: 93.164 (Average: 93.164)\n",
      "Epoch: No: [78] Batches: [50/98]\tLoss: 0.2075 (Average: 0.2033)\tPrecision: 93.359 (Average: 92.934)\n",
      "Test Accuracy\t  Top Precision: 85.960 (Error: 14.040 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [79] Batches: [0/98]\tLoss: 0.2285 (Average: 0.2285)\tPrecision: 93.359 (Average: 93.359)\n",
      "Epoch: No: [79] Batches: [50/98]\tLoss: 0.1864 (Average: 0.2014)\tPrecision: 93.945 (Average: 92.896)\n",
      "Test Accuracy\t  Top Precision: 87.200 (Error: 12.800 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [80] Batches: [0/98]\tLoss: 0.1946 (Average: 0.1946)\tPrecision: 92.578 (Average: 92.578)\n",
      "Epoch: No: [80] Batches: [50/98]\tLoss: 0.1648 (Average: 0.1949)\tPrecision: 94.141 (Average: 93.149)\n",
      "Test Accuracy\t  Top Precision: 85.790 (Error: 14.210 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [81] Batches: [0/98]\tLoss: 0.2619 (Average: 0.2619)\tPrecision: 90.820 (Average: 90.820)\n",
      "Epoch: No: [81] Batches: [50/98]\tLoss: 0.2043 (Average: 0.2039)\tPrecision: 92.773 (Average: 92.888)\n",
      "Test Accuracy\t  Top Precision: 86.490 (Error: 13.510 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [82] Batches: [0/98]\tLoss: 0.1849 (Average: 0.1849)\tPrecision: 93.750 (Average: 93.750)\n",
      "Epoch: No: [82] Batches: [50/98]\tLoss: 0.2526 (Average: 0.1902)\tPrecision: 91.797 (Average: 93.187)\n",
      "Test Accuracy\t  Top Precision: 85.690 (Error: 14.310 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [83] Batches: [0/98]\tLoss: 0.1881 (Average: 0.1881)\tPrecision: 93.750 (Average: 93.750)\n",
      "Epoch: No: [83] Batches: [50/98]\tLoss: 0.2166 (Average: 0.1863)\tPrecision: 92.578 (Average: 93.428)\n",
      "Test Accuracy\t  Top Precision: 86.690 (Error: 13.310 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [84] Batches: [0/98]\tLoss: 0.1959 (Average: 0.1959)\tPrecision: 94.141 (Average: 94.141)\n",
      "Epoch: No: [84] Batches: [50/98]\tLoss: 0.2132 (Average: 0.1828)\tPrecision: 91.797 (Average: 93.650)\n",
      "Test Accuracy\t  Top Precision: 86.610 (Error: 13.390 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [85] Batches: [0/98]\tLoss: 0.1769 (Average: 0.1769)\tPrecision: 93.555 (Average: 93.555)\n",
      "Epoch: No: [85] Batches: [50/98]\tLoss: 0.1752 (Average: 0.1918)\tPrecision: 94.141 (Average: 93.256)\n",
      "Test Accuracy\t  Top Precision: 86.140 (Error: 13.860 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [86] Batches: [0/98]\tLoss: 0.1783 (Average: 0.1783)\tPrecision: 93.359 (Average: 93.359)\n",
      "Epoch: No: [86] Batches: [50/98]\tLoss: 0.1846 (Average: 0.1947)\tPrecision: 92.773 (Average: 93.110)\n",
      "Test Accuracy\t  Top Precision: 86.590 (Error: 13.410 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [87] Batches: [0/98]\tLoss: 0.1612 (Average: 0.1612)\tPrecision: 93.750 (Average: 93.750)\n",
      "Epoch: No: [87] Batches: [50/98]\tLoss: 0.2295 (Average: 0.1858)\tPrecision: 90.820 (Average: 93.417)\n",
      "Test Accuracy\t  Top Precision: 86.110 (Error: 13.890 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [88] Batches: [0/98]\tLoss: 0.1922 (Average: 0.1922)\tPrecision: 93.164 (Average: 93.164)\n",
      "Epoch: No: [88] Batches: [50/98]\tLoss: 0.1790 (Average: 0.1824)\tPrecision: 92.969 (Average: 93.493)\n",
      "Test Accuracy\t  Top Precision: 86.430 (Error: 13.570 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [89] Batches: [0/98]\tLoss: 0.1739 (Average: 0.1739)\tPrecision: 93.945 (Average: 93.945)\n",
      "Epoch: No: [89] Batches: [50/98]\tLoss: 0.1622 (Average: 0.1750)\tPrecision: 93.164 (Average: 93.857)\n",
      "Test Accuracy\t  Top Precision: 85.750 (Error: 14.250 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [90] Batches: [0/98]\tLoss: 0.1904 (Average: 0.1904)\tPrecision: 92.969 (Average: 92.969)\n",
      "Epoch: No: [90] Batches: [50/98]\tLoss: 0.2280 (Average: 0.1839)\tPrecision: 91.211 (Average: 93.294)\n",
      "Test Accuracy\t  Top Precision: 85.340 (Error: 14.660 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [91] Batches: [0/98]\tLoss: 0.2221 (Average: 0.2221)\tPrecision: 93.750 (Average: 93.750)\n",
      "Epoch: No: [91] Batches: [50/98]\tLoss: 0.2093 (Average: 0.1738)\tPrecision: 93.555 (Average: 93.884)\n",
      "Test Accuracy\t  Top Precision: 87.370 (Error: 12.630 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [92] Batches: [0/98]\tLoss: 0.1651 (Average: 0.1651)\tPrecision: 93.945 (Average: 93.945)\n",
      "Epoch: No: [92] Batches: [50/98]\tLoss: 0.2126 (Average: 0.1641)\tPrecision: 93.164 (Average: 94.114)\n",
      "Test Accuracy\t  Top Precision: 86.900 (Error: 13.100 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [93] Batches: [0/98]\tLoss: 0.1805 (Average: 0.1805)\tPrecision: 92.578 (Average: 92.578)\n",
      "Epoch: No: [93] Batches: [50/98]\tLoss: 0.1227 (Average: 0.1697)\tPrecision: 95.898 (Average: 94.148)\n",
      "Test Accuracy\t  Top Precision: 86.580 (Error: 13.420 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [94] Batches: [0/98]\tLoss: 0.1437 (Average: 0.1437)\tPrecision: 94.531 (Average: 94.531)\n",
      "Epoch: No: [94] Batches: [50/98]\tLoss: 0.1459 (Average: 0.1706)\tPrecision: 95.508 (Average: 93.922)\n",
      "Test Accuracy\t  Top Precision: 86.970 (Error: 13.030 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [95] Batches: [0/98]\tLoss: 0.1187 (Average: 0.1187)\tPrecision: 95.312 (Average: 95.312)\n",
      "Epoch: No: [95] Batches: [50/98]\tLoss: 0.1050 (Average: 0.1678)\tPrecision: 94.727 (Average: 93.957)\n",
      "Test Accuracy\t  Top Precision: 85.770 (Error: 14.230 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [96] Batches: [0/98]\tLoss: 0.1561 (Average: 0.1561)\tPrecision: 93.359 (Average: 93.359)\n",
      "Epoch: No: [96] Batches: [50/98]\tLoss: 0.1933 (Average: 0.1672)\tPrecision: 93.359 (Average: 94.033)\n",
      "Test Accuracy\t  Top Precision: 85.670 (Error: 14.330 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [97] Batches: [0/98]\tLoss: 0.2524 (Average: 0.2524)\tPrecision: 92.578 (Average: 92.578)\n",
      "Epoch: No: [97] Batches: [50/98]\tLoss: 0.1500 (Average: 0.1640)\tPrecision: 94.531 (Average: 94.275)\n",
      "Test Accuracy\t  Top Precision: 86.130 (Error: 13.870 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [98] Batches: [0/98]\tLoss: 0.1180 (Average: 0.1180)\tPrecision: 95.898 (Average: 95.898)\n",
      "Epoch: No: [98] Batches: [50/98]\tLoss: 0.1648 (Average: 0.1591)\tPrecision: 93.359 (Average: 94.424)\n",
      "Test Accuracy\t  Top Precision: 86.130 (Error: 13.870 )\n",
      "\n",
      "Training model: Model 1\n",
      "Current Learning Rate 1.00000e-01\n",
      "Epoch: No: [99] Batches: [0/98]\tLoss: 0.1812 (Average: 0.1812)\tPrecision: 93.945 (Average: 93.945)\n",
      "Epoch: No: [99] Batches: [50/98]\tLoss: 0.2459 (Average: 0.1701)\tPrecision: 92.773 (Average: 94.064)\n",
      "Test Accuracy\t  Top Precision: 85.570 (Error: 14.430 )\n",
      "\n",
      "The lowest error from model: Model 1 after 100 epochs is 12.630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args=ResNetParams()\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "best_precision = 0\n",
    "best_precision = run_epochs()\n",
    "print('The lowest error from model: {} after {} epochs is {error:.3f}'.format(args.arch,args.epochs, error=100-best_precision))\n",
    "model_save_name = 'project1_model.pt'\n",
    "#path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
    "\n",
    "#Saving the generated model and testing its loading\n",
    "path = model_save_name\n",
    "torch.save(model.state_dict(), path) \n",
    "model_path = path\n",
    "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00a0c9c-eb50-475f-9682-4cd323a5ae59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the model\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.plot(val_losses,label=\"Val\")\n",
    "plt.plot(train_losses,label=\"Train\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('plot_graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "22cf10741174a73c16493d470940eeed718720095727e52348075ea0a9a6dd40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
